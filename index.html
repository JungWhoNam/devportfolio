<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Jung Who Nam's Portfolio</title>
	<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
</head>

<body>
    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            <li>
                <a href="#about">About</a>
            </li>
            <li>
                <a href="#education">Education</a>
            </li>
            <li>
                <a href="#publication">Publications</a>
            </li>
            <li>
                <a href="#experience">Experience</a>
            </li>
            <li>
                <a href="#skills">Skills</a>
            </li>
            <li>
                <a href="#about">Contact</a>
            </li>
        </ul>
    </header>
    <!-- End header -->

    <div id="lead">
        <div id="lead-content">
            <h1>Jung Who Nam</h1>
            <h2>PhD Graduate - Computer Science</h2>
            <a href="images/JungWhoNam_Resume.pdf" class="btn-rounded-white" target="_blank">Resume</a>
            &nbsp;&nbsp;
            <a href="https://summer-broom-729.notion.site/Jung-Who-Nam-5b832cc47651442eb4b9b9d4526dace4" class="btn-rounded-white" target="_blank">이력서</a>
            <!-- &nbsp;&nbsp;
            <a href="https://summer-broom-729.notion.site/Jung-Who-Nam-4d641737ebd947908a65ce3d4152f434" class="btn-rounded-white" target="_blank">포트폴리오</a> -->
        </div>
        <!-- End #lead-content -->

        <div id="lead-overlay"></div>

        <div id="lead-down">
            <span>
                <i class="fa fa-chevron-down" aria-hidden="true"></i>
            </span>
        </div>
        <!-- End #lead-down -->
    </div>
    <!-- End #lead -->

    <div id="about">
        <div class="container">
            <div class="row">
                <div class="col-md-4 contact">
                    <h2 class="name">Jung Who Nam</h2>
                    <div>
                        <img src="images/mugshot.jpg"/>
                    </div>
                    <a href="mailto:jungwhonam@gmail.com">jungwhonam@gmail.com</a>
                    <div class="social">
                        <ul>
                            <li>
                                <a href="https://scholar.google.com/citations?user=L923bnYAAAAJ&hl=en" target="_blank"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a>
                            </li>
                            <li>
                                <a href="https://github.com/jungwhonam" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/jungwhonam/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
                            </li>
                        </ul>
                    </div>
                    <!-- <a href="images/CV_JungWhoNam.pdf" class="btn-rounded" target="_blank">Download CV</a> -->
                </div>
                <div class="col-md-8">
                    <h2 class="heading">About Me</h2>
                    <p>
                        I am an assistant professor in the Computer Science department at <a href="https://www.kunsan.ac.kr/" target="_blank">Kunsan National University</a>, South Korea.
                        I earned my Ph.D. at the University of Minnesota under Professor <a href="https://ivlab.cs.umn.edu/" target="_blank">Daniel F. Keefe</a>.
                        I did a postdoc at the <a href="https://www.tacc.utexas.edu/" target="_blank">Texas Advanced Computing Center</a>, where I worked on extending Intel's raytracing applications to support immersive virtual reality experiences. 
                        From 2019 to 2022, I created interactive museum installations in South Korea, providing innovative ways to explore historical data.
                        
                        <br><br>
                        My research interests include scientific visualization, immersive analytics, and data storytelling. 
                        I specialize in designing and developing 3D user interaction techniques to empower experts across various domains to explore and present their data. 
                        
                        <br><br>Below, you can explore several projects I have developed throughout my research career.
                    </p>
                </div>
            </div>
        </div>
    </div>
    <!-- End #about -->

    <div id="education" class="background-alt">
        <h2 class="heading">Education</h2>
        <div class="education-block">
            <h3>University of Minnesota, Twin Cities</h3>
            <span class="education-date">2014 – July 2022</span>
            <h4>Ph.D. in Computer Science</h4>
            <ul>
                <li>Advisor: Daniel F. Keefe (<a href=https://ivlab.cs.umn.edu/ target="_blank">IVLab</a>)</li>
                <li>Dissertation Title: Everyday Scientific Visualization: Making 3D Visualization Techniques Accessible for Day-To-Day Team-Science for Collaboration and Analysis</li>
                <!-- <li>Notes: Took a three-year of leave of absence for the mandatory army service (2019-2022)</li> -->
                <li>Specializations: Data Visualization, Virtual Reality, Data Storytelling, Data Collaboration</li>
            </ul>
        </div>
        <!-- End .education-block -->
        <div class="education-block">
            <h3>University of Minnesota, Twin Cities</h3>
            <span class="education-date">2012 – 2014</span>
            <h4>M.S. in Computer Science</h4>
            <ul>
                <li>Specializations: Computer Graphics, Virtual Reality</li>
            </ul>
        </div>
        <!-- End .education-block -->
        <div class="education-block">
            <h3>University of Minnesota, Twin Cities</h3>
            <span class="education-date">2008 – 2012</span>
            <h4>B.S. in Computer Science</h4>
            <ul>
                <li>Specializations: Computer Graphics, User Interfaces</li>
            </ul>
        </div>
        <!-- End .education-block -->
    </div>
    <!-- End #education -->

    <div id="publication">
        <h2 class="heading">Publications</h2>
        <div class="pub-legend">
            <ul>
                <li><p class="pub-type journal pub-legned-type">Journal articles</p></li>
                <li><p class="pub-type conference pub-legned-type">Conference papers</p></li>
                <li><p class="pub-type book pub-legned-type">Book chapters</p></li>
                <li><p class="pub-type abstract pub-legned-type">Abstracts, Workshops, Exhibits, Posters</p></li>
                <li><p class="pub-type award pub-legned-type">Awards</p></li>
            </ul>
        </div>
        <div class="container">
            <!-- PEARC 2023 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/PEARC2023_Immersive-OSPRay.jpeg">
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type conference">PEARC 2023</p></li>
                    </ul>
                    <p class="pub-title">Immersive OSPRay: Enabling VR Experiences with OSPRay</p>
                    <p class="pub-author"><b>Jung Who Nam</b>, Gregory D. Abram, Francesca Samsel, and Paul A. Navrátil</p>
                    <p class="pub-venue">ACM PEARC 2023, Portland, USA. (DOI: <a href="https://doi.org/10.1145/3569951.3597579" target="_blank">10.1145/3569951.3597579</a>)</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="images/publications/PEARC2023_Immersive-OSPRay.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- TVCG 2022 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/TVCG2023_V-Mail.jpg">
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type journal">TVCG</p></li>
                    </ul>
                    <p class="pub-title">V-Mail: 3D-Enabled Correspondence about Spatial Data on (Almost) All Your Devices</p>
                    <p class="pub-author"><b>Jung Who Nam</b>, Tobias Isenberg, and Daniel F. Keefe</p>
                    <p class="pub-venue">IEEE Transactions on Visualization and Computer Graphics, 2022. (DOI: <a href="https://doi.org/10.1109/TVCG.2022.3229017" target="_blank">10.1109/TVCG.2022.3229017</a>)</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="images/publications/TVCG2023_V-Mail.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li>
                            <li><a href="https://www.youtube.com/watch?v=SCTlARovRBY&ab_channel=InteractiveVisualizationLab" target="_blank"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- Book 2022 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/Book2022_Prop-Interfaces-Pen.png">
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type book">Book chapter</p></li>
                    </ul>
                    <p class="pub-title">Hybrid Data Constructs: Interacting with Biomedical Data in Augmented Spaces</p>
                    <p class="pub-author">Daniel F. Keefe, Bridger Herman, <b>Jung Who Nam</b>, Daniel Orban, and Seth Johnson</p>
                    <p class="pub-venue">In Making Data: Materializing Digital Information, edited by Ian Gwilt, ch. 11, pp. 169-182, Bloomsbury Visual Arts, June 2022. (DOI: <a href="https://doi.org/10.5040/9781350133266.ch-011" target="_blank">10.5040/9781350133266.ch-011</a>)</p>
                    <div class="pub-link">
                        <ul>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- VR 2019 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/VR2019_Worlds-in-Wedges.jpg"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type conference">VR 2019</p></li>
                    </ul>
                    <p class="pub-title">Worlds-in-Wedges: Combining WIMs and Portals to Support Comparative Immersive Visualization of Forestry Data</p>
                    <p class="pub-author"><b>Jung Who Nam</b>, Krista McCullough, Joshua Tveite, Maria M. Espinosa, Charles H. Perry, Barry T. Wilson, and Daniel F. Keefe</p>
                    <p class="pub-venue">IEEE VR 2019, Osaka, Japan. (DOI: <a href="https://doi.org/10.1109/VR.2019.8797871" target="_blank">10.1109/VR.2019.8797871</a>)</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="https://www.fs.usda.gov/treesearch/treesearch/pubs/download/61979.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li>
                            <li><a href="https://www.youtube.com/watch?v=okRE3JHs4SE&ab_channel=InteractiveVisualizationLab" target="_blank"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></li>
                            <li><a href="https://www.youtube.com/watch?v=9l2vjI8njSI&ab_channel=IEEEVirtualReality2019Recording" target="_blank"><i class="fa fa-video-camera" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- Nature 2019 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/Nature2019_prostate-cancer.jpg"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type journal">Nature Scientific Reports</p></li>
                    </ul>
                    <p class="pub-title">Signature Maps for Automatic Identification of Prostate Cancer from Colorimetric Analysis of H&E-and IHC-stained Histopathological Specimen</p>
                    <p class="pub-author">Ethan Leng, Jonathan C. Henriksen, Anthony E. Rizzardi, Jin Jin, <b>Jung Who Nam</b>, Benjamin M. Brassuer, Andrew D. Johnson, Nicholas P. Reder, Joseph S. Koopmeiners, Stephen C. Schmechel, and Gregory J. Metzger</p>
                    <p class="pub-venue">Nature Scientific Reports, vol. 9, no. 6992, May 2019. (DOI: <a href="https://doi.org/10.1038/s41598-019-43486-y" target="_blank">10.1038/s41598-019-43486-y</a>)</p>
                    <div class="pub-link">
                        <ul>
                            <!-- <li><a href="https://www.nature.com/articles/s41598-019-43486-y.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li> -->
                        </ul>
                    </div>
                </div>
            </div>
            <!-- VIS 2019 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/VIS2019_Linked-View-MobileVR.jpg"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type abstract">SciVis 2019 posters</p></li>
                        <li><p class="pub-type award"><i>SciVis Best Poster Award</i></p></li>
                    </ul>
                    <p class="pub-title">Linked View Visualization Using Clipboard-Style Mobile VR: Application to Communicating Forestry Data</p>
                    <p class="pub-author"><b>Jung Who Nam</b>, Charles H. Perry, Barry T. Wilson, and Daniel F. Keefe</p>
                    <p class="pub-venue">IEEE VIS 2019, Vancouver, Canada.</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="images/publications/VIS2019_Linked-View-MobileVR (abstract).pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li>
                            <li><a href="https://www.youtube.com/watch?v=vhv6tA6IIUk&ab_channel=InteractiveVisualizationLab" target="_blank"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></li>
                            <li><a href="images/publications/VIS2019_Linked-View-MobileVR (poster).pdf" target="_blank"><i class="fa fa-file-powerpoint-o" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- VRST 2019 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/VRST2019_museum.jpg"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type abstract">VRST 2019 posters</p></li>
                    </ul>
                    <p class="pub-title">Effects of Age and Motivation for Visiting on AR Museum Experiences</p>
                    <p class="pub-author">Narae Park, Yohan Hong, Hyunjeong Pak, <b>Jung Who Nam</b>, Kyoungsu Kim, Junbom Pyo, Kyungwon Gil, and Kyoobin Lee</p>
                    <p class="pub-venue">ACM VRST 2019, Sydney, Australia. (DOI: <a href="https://doi.org/10.1145/3359996.3364711" target="_blank">10.1145/3359996.3364711</a>)</p>
                    <div class="pub-link">
                        <ul>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- Leonardo 2017 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/VISAP2014_Spatial-Correlation.png"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type journal">Leonardo</p></li>
                    </ul>
                    <p class="pub-title">Spatial Correlation: An Interactive Display of Virtual Gesture Sculpture</p>
                    <p class="pub-author"><b>Jung Who Nam</b> and Daniel F. Keefe</p>
                    <p class="pub-venue">Leonardo, vol. 50, no. 1, pp. 94–95, Feb 2017. (DOI: <a href="https://doi.org/10.1162/LEON_a_01226" target="_blank">10.1162/LEON_a_01226</a>)</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="https://www.youtube.com/watch?v=_0ffZbVUWWE&ab_channel=JungWhoNam" target="_blank"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- Nature 2016 -->
            <hr>
            <div class="row"> 
                <div class="col-md-4">
                    <img src="images/publications/Nature2016_diffusion-MRI.jpg"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type journal">Nature Scientific Reports</p></li>
                    </ul>
                    <p class="pub-title">Microstructure Imaging of Crossing (MIX) White Matter Fibers from diffusion MRI</p>
                    <p class="pub-author">Hamza Farooq, Junqian Xu, <b>Jung Who Nam</b>, Daniel F. Keefe, Essa Yacoub, Tryphon Georgiou, and Christophe Lenglet</p>
                    <p class="pub-venue">Nature Scientific Reports, vol. 6, no. 38927, Dec 2016. (DOI: <a href="https://doi.org/10.1038/srep38927" target="_blank">10.1038/srep38927</a>)</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="https://www.nature.com/articles/srep38927.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- Radiology 2016-->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/Radiology216_prostate-cancer.jpg"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type journal">Radiology</p></li>
                    </ul>
                    <p class="pub-title">Detection of Prostate Cancer: Quantitative Multiparametric MR Imaging Models Developed Using Registered Correlative Histopathology</p>
                    <p class="pub-author">Gregory J. Metzger , Chaitanya Kalavagunta, Benjamin Spilseth, Patrick J. Bolan, Xiufeng Li, Diane Hutter, <b>Jung Who Nam</b>, Andrew D. Johnson, Jonathan C. Henriksen, Laura Moench, Badrinath Konety, Christopher A. Warlick, Stephen C. Schmechel, and Joseph S. Koopmeiners</p>
                    <p class="pub-venue">Radiology, vol. 279, no. 3, pp. 805-816, Jan 2016. (DOI: <a href="https://doi.org/10.1148/radiol.2015151089" target="_blank">10.1148/radiol.2015151089</a>)</p>
                    <div class="pub-link">
                        <ul>
                        </ul>
                    </div>
                </div>
            </div>
            <!-- VISAP 2014 -->
            <hr>
            <div class="row">
                <div class="col-md-4">
                    <img src="images/publications/VISAP2014_Spatial-Correlation.png"/>
                </div>
                <div class="col-md-8 pub-info">
                    <ul>
                        <li><p class="pub-type abstract">VISAP exhibits</p></li>
                    </ul>
                    <p class="pub-title">Spatial Correlation: An Interactive Display of Virtual Gesture Sculpture</p>
                    <p class="pub-author"><b>Jung Who Nam</b> and Daniel F. Keefe</p>
                    <p class="pub-venue">IEEE VIS 2014 Arts Program, Paris, France.</p>
                    <div class="pub-link">
                        <ul>
                            <li><a href="https://visap.uic.edu/2014/papers/09_Nam_SpatialCorrelation_VISAP2014.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a></li>
                            <li><a href="https://www.youtube.com/watch?v=_0ffZbVUWWE&ab_channel=JungWhoNam" target="_blank"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- End #publication -->

    <div id="experience" class="background-alt">
        <h2 class="heading">Experience</h2>
        <div id="experience-timeline">
            <div data-date="2024.10 – Present </br>">
                <h3>Kunsan National University - South Korea</h3>
                <h4>Assistant Professor, Computer Science Department</h4>
                <p><u>Courses</u></p>
                <ul>
                    <li>
                        Computer Graphics (Fall 2024)
                    </li>
                    <li>
                        Object Oriented Programming (Fall 2024)
                    </li>
                </ul>
            </div>
            <div data-date="2022 – 2024 </br> (1 yr 10 mos)">
                <h3>University of Texas - Austin, TX</h3>
                <h4>Postdoctoral Researcher, Texas Advanced Computing Center (TACC)</h4>
                <p>
                    At the visitor center, there are high-res tiled displays that show images and videos from visualization projects that researchers at the center have worked on. 
                    My task is to bring interactive 3D content into the systems to provide visitors with engaging methods to look at ongoing work. 
                    Working with software engineers at Intel and research scientists at TACC, I upgraded Intel's raytracing application to display a single, coherent 3D virtual environment on the tiled displays and added support for gesture-based interaction. 
                    We created a proof-of-concept prototype that enables a user to move around a 3D virtual environment by lifting both hands - pretending to be a bird - and leaning the body to fly in that direction.
                    <!-- <br><br>
                    Additionally, for this year, I will implement voice-control capabilities in the application so that users can move around a 3D environment using spoken words. 
                    We plan to leverage recent advances in deep learning models to develop this interactive system.
                    Our initial prototype will provide an example of AI agents used for real-time applications such as data visualizations and provide opportunities to test current deep learning models for verbally interacting with 3D content. -->
                </p>
                <br><p><u>Collaborative Results</u></p>
                <ul>
                    <li>
                        "Immersive OSPRay: Enabling VR Experiences with OSPRay" 
                        (<a href="https://doi.org/10.1145/3569951.3597579" target="_blank">10.1145/3569951.3597579</a>)
                    </li>
                </ul>
            </div>
            <div data-date="2019 – 2021 </br> (2 yrs 6 mos)">
                <h3>Gwangju Institute of Science and Technology - South Korea</h3>
                <h4>Research Engineer, Korea Culture and Technology Institute (KCTI)</h4>
                <p>
                    During my stay in South Korea, I worked in a lab that works closely with museums to support new generations of public exhibitions. 
                    My task was to develop interactive installations for museums by closely working with experts from other fields, e.g., graphic designers, data curators, and historians. I developed visualization and interaction techniques for use by museum visitors to explore museums' archived data using gesture-based interaction. 
                    To ease the process of integrating assets created by designers and data curators, I implemented features to load the assets and populate 3D scenes and GUIs. 
                    By refactoring the code, I also provided a codebase for gesture-based interaction in Unity, which enabled another developer to create separate interactive applications. During my stay, I helped create two interactive installations presented at public venues (each lasted about a week).
                </p>
                <br><p><u>Collaborative Results</u></p>
                <ul>
                    <li>
                        "The Road of Hyecho" - Interactive installation at Gwangju Cultural Foundation
                        (<a href=http://www.aitimes.com/news/articleView.html?idxno=141438 target="_blank">news</a>)
                    </li>
                    <li>
                        "The Road of Ramayana" - Interactive installation at Asia Culture Center
                        (<a href=https://www.youtube.com/watch?v=xQncwrlOdUM&ab_channel=%ED%95%9C%EA%B5%AD%EB%AC%B8%ED%99%94%EA%B8%B0%EC%88%A0%EC%97%B0%EA%B5%AC%EC%86%8C_GIST target="_blank">video</a>, 
                        <a href=https://www.etnews.com/20201214000012 target="_blank">news</a>,
                        <a href=https://www.newsworks.co.kr/news/articleView.html?idxno=511680 target="_blank">news</a>)
                    </li>
                    <li>
                        "Effects of Age and Motivation for Visiting on AR Museum Experiences"
                        (<a href="https://doi.org/10.1145/3359996.3364711" target="_blank">10.1145/3359996.3364711</a>)
                    </li>
                </ul>
            </div>
            <div data-date="2014 – 2019 </br> (4 yrs 9 mos)">
                <h3>University of Minnesota - Twin Cities, Minneapolis, MN</h3>
                <h4>Research Assistant, Interactive Visualization Lab (IVLab)</h4>
                <p>
                    During my Ph.D., I worked with experts from other fields, e.g., geology, medical devices, neuroscience, and health. 
                    My task was to create 3D interactive systems to assist these experts with analyzing and presenting their data. 
                    Mainly, I worked on creating data-driven 3D virtual environments and integrating VR/AR technologies to enable these experts to immerse in data (and look for findings and confirm hypotheses). 
                    Also, focusing on public-facing content, I worked on creating VR solutions to make these technologies accessible to the public for training and education. 
                    These works were presented at IEEE VR and VIS conferences.
                </p>
                <br><p><u>Collaborative Results</u></p>
                <ul>
                    <li>
                        "Worlds-in-Wedges: Combining WIMs and Portals to Support Comparative Immersive Visualization of Forestry Data" 
                        (<a href="https://doi.org/10.1109/VR.2019.8797871" target="_blank">10.1109/VR.2019.8797871</a>)
                    </li>
                    <li>
                        "Linked View Visualization Using Clipboard-Style Mobile VR: Application to Communicating Forestry Data" 
                        <a href="images/publications/VIS2019_Linked-View-MobileVR (abstract).pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                    </li>
                    <li>
                        "Hybrid Data Constructs: Interacting with Biomedical Data in Augmented Spaces" 
                        (<a href="https://doi.org/10.5040/9781350133266.ch-011" target="_blank">10.5040/9781350133266.ch-011</a>)
                    </li>
                    <li>
                        "Spatial Correlation: An Interactive Display of Virtual Gesture Sculpture" 
                        (<a href="https://doi.org/10.1162/LEON_a_01226" target="_blank">10.1162/LEON_a_01226</a>)
                    </li>
                    <li>
                        "Microstructure Imaging of Crossing (MIX) White Matter Fibers from diffusion MRI" 
                        (<a href="https://doi.org/10.1038/srep38927" target="_blank">10.1038/srep38927</a>)
                    </li>
                </ul>
            </div>
            <div data-date="Summer 2018 </br> (3 mos)">
                <h3>INRIA - Scalay, France</h3>
                <h4>Research Intern, Analysis and Visualization Lab (AVIZ)</h4>
                <p>
                    Scientific visualization applications are often complex, requiring substantial expertise in how to use software features. 
                    My task was to find ways of facilitating team-science collaboration even when members have different levels of expertise. 
                    Our approach is to provide different ways of viewing/interacting with data in one collaborative framework. 
                    Data can simply be viewed from a video file created using animation features we developed. 
                    More engaged users can load the same video file in a visualization application and thoroughly explore the depicted data. 
                    Traveling users can see the video file in our custom video player and sketch or leave comments on data views. 
                    With this framework, users can pick and choose a client based on their needs and situations, and importantly, changes made in these clients are made back to the original data, so everyone is in sync. 
                    This work was published in TVCG.
                </p>
                <br><p><u>Collaborative Results</u></p>
                <ul>
                    <li>
                        "V-Mail: 3D-Enabled Correspondence about Spatial Data on (Almost) All Your Devices" 
                        (<a href="https://doi.org/10.1109/TVCG.2022.3229017" target="_blank">10.1109/TVCG.2022.3229017</a>)
                    </li>
                </ul>
            </div>
            <!-- <div data-date="2015 & 2018">
                <h3>University of Minnesota - Twin Cities, Minneapolis, MN</h3>
                <h4>Teaching Assistant, Computer Science Department</h4>            
                <ul>
                    <li>CSCI 4611 Programming Interactive Computer Graphics and Games (Spring 2018)</li>
                    <li>CSCI 5609 Visualization (Spring 2015)</li>
                </ul>
            </div> -->
            <div data-date="2011 – 2014 </br> (3 yrs 3 mos)">
                <h3>University of Minnesota - Twin Cities, Minneapolis, MN</h3>
                <h4>Programmer, Center for Magnetic Resonance Research (CMRR)</h4>            
                <p>
                    When a patient is diagnosed with prostate cancer, the organ is taken out of the body. 
                    To study cancer, pathologists cut the prostate into slices and further cut it into subsections to be able to scan these tissues with scanning devices. 
                    My task was to develop a series of tools to assist pathologists with reconstructing a prostate volume and making further annotations. 
                    I helped create a Photoshop-like application that enabled pathologists to stitch back these scanned images and draw cancer boundaries. 
                    I also implemented output features to save these annotated slice images to a file format for further data analysis. 
                    Researchers in the lab used these annotated data to create models for detecting prostate cancer; their works were published in Nature Scientific Reports and Radiology.
                </p>
                <br><p><u>Collaborative Results</u></p>
                <ul>
                    <li>
                        "Signature Maps for Automatic Identification of Prostate Cancer from Colorimetric Analysis of H&E-and IHC-stained Histopathological Specimen" 
                        (<a href="https://doi.org/10.1038/s41598-019-43486-y" target="_blank">10.1038/s41598-019-43486-y</a>)
                    </li>
                    <li>
                        "Detection of Prostate Cancer: Quantitative Multiparametric MR Imaging Models Developed Using Registered Correlative Histopathology" 
                        (<a href="https://doi.org/10.1148/radiol.2015151089" target="_blank">10.1148/radiol.2015151089</a>)
                    </li>
                </ul>
            </div>
        </div>
    </div>
    <!-- End #experience -->

    <div id="skills">
        <h2 class="heading">Skills</h2>
        <ul>
            <li>C#</li>
            <li>C++</li>
            <li>Python</li>
            <li>Unity</li>
            <li>Git</li>
            <li>OptiTrack</li>
            <li>Microsoft Kinect</li>
            <li>Leap Motion</li>
            <li>HMD VR</li>
            <li>CAVE VR</li>
            <li>Large Tiled Displays</li>
            <li>Photoshop</li>
        </ul>
    </div>
    <!-- End #skills -->

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
                    <p>
                        <!-- Copyright &copy; 2022 Jung Who Nam -->
                        Jung Who Nam
                        <br>Last updated on Feb 09, 2025
                    </p>
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>

                <div class="col-sm-5 social">
                    <ul>
                    </ul>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.js"></script>
</body>

</html>
