<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Jung Who Nam's Portfolio</title>
	<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
</head>

<body>
    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            <li>
                <a href="#about">About</a>
            </li>
            <li>
                <a href="#projects">Projects</a>
            </li>
            <li>
                <a href="#education">Education</a>
            </li>
            <li>
                <a href="#experience">Experience</a>
            </li>
            <li>
                <a href="#skills">Skills</a>
            </li>
            <li>
                <a href="#publication">Publications</a>
            </li>
            <li>
                <a href="#contact">Contact</a>
            </li>
        </ul>
    </header>
    <!-- End header -->

    <div id="lead">
        <div id="lead-content">
            <h1>Jung Who Nam</h1>
            <h2>PhD Student - Computer Science</h2>
            <a href="images/CV_JungWhoNam.pdf" class="btn-rounded-white">Download CV</a>
        </div>
        <!-- End #lead-content -->

        <div id="lead-overlay"></div>

        <div id="lead-down">
            <span>
                <i class="fa fa-chevron-down" aria-hidden="true"></i>
            </span>
        </div>
        <!-- End #lead-down -->
    </div>
    <!-- End #lead -->

    <div id="about">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <h2 class="heading">About Me</h2>
                </div>
                <div class="col-md-8">
                    <p>
                        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur in iaculis ex. Etiam volutpat laoreet urna. Morbi ut tortor nec nulla commodo malesuada sit amet vel lacus. Fusce eget efficitur libero. Morbi dapibus porta quam laoreet placerat. Donec
                        eu vehicula neque. Donec viverra lorem nunc, tempus euismod eros sollicitudin ut. Quisque et tincidunt libero. Donec id pharetra justo. Proin euismod lacinia dolor, eu scelerisque justo tempus pharetra. Vivamus nunc justo, finibus
                        ut nisl sed, euismod rhoncus nulla. Proin sed magna egestas, egestas ante et, congue eros. In consequat, mauris dapibus tincidunt suscipit, ex libero aliquet diam, at maximus risus enim non leo.
                    </p>
                </div>
            </div>
        </div>
    </div>
    <!-- End #about -->

    <div id="projects" class="background-alt">
        <h2 class="heading">Projects</h2>
        <div class="container">
            <div class="row">
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/Worlds-in-Wedges.png"/>
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Comparative Immersive Visualization of Spatial 3D Data</h3>
                        <p>
                            Virtual reality (VR) environments are typically designed so users feel present in a single virtual world at a time, but this creates a problem for applications that require visual comparisons (e.g., forest scientists comparing multiple data-driven virtual forests). To address this, we developed a 3D user interface and visualization technique that divides the virtual space surrounding the viewer into pie-slice shaped volumetric wedges and fills each wedge with a different virtual world. By stacking the wedges around a common axis and placing the tracked user at the center, it is possible to create an immersive juxtaposition of spatial data, where the user may look around, using head-tracked stereoscopic graphics to compare multiple worlds. The interface supports navigation, selection, and view manipulation.
                        </p>
                    </div>
                    <!-- End .project-info -->
                    <div class="project-detail">
                        <hr>
                        <div class ="video-frame">
                            <iframe src="https://www.youtube.com/embed/okRE3JHs4SE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </div>
                        <hr>
                        <div>
                            <h4> Conference Article </h4>
                            <p>
                                Jung Who Nam, Krista McCullough, Joshua Tveite, Maria M. Espinosa, Charles H. Perry, Barry T. Wilson, Daniel F. Keefe. “Worlds-in-Wedges: Combining WIMs and Portals to Support Comparative Immersive Visualization of Forestry Data”. IEEE VR, Mar 2019.
                            </p>
                            <h5>Abstract</h5>
                            <p>
                                Virtual reality (VR) environments are typically designed so users feel present in a single virtual world at a time, but this creates a problem for applications that require visual comparisons (e.g., forest scientists comparing multiple data-driven virtual forests). To address this, we present Worlds-in-Wedges, a 3D user interface and visualization technique that supports comparative immersive visualization by dividing the virtual space surrounding the user into volumetric wedges. There are three visual/interactive levels. The first, worlds-in-context, visualizes high-level relationships between the worlds (e.g., a map for worlds that are related in space). The second level, worlds-in-miniature, is a multi-instance implementation of the World-in-Miniature technique extended to support mutlivariate glyph visualization. The third level, worlds-in-wedges, displays multiple large-scale worlds in wedges that act as volumetric portals. The interface supports navigation, selection, and view manipulation. Since the techniques were inspired directly by problems facing forest scientists, the interface was evaluated by building a complete multivariate data visualization of the US Forest Service Forest Inventory and Analysis public dataset. Scientist user feedback and lessons from iterative design are reported.
                            </p>
                        </div>
                        <hr>
                        <div>
                            <h4>My Role </h4>
                            <p>
                                Through regular meetings with our forestry researcher collaborators, I and my advisor designed and developed the World-in-Wedges technique to support simultaneous comparisons of multiple data-driven virtual worlds. I worked closely with two undergraduate students: an art student who designed data glyphs and a computer science student implemented elevations of terrains.
                            </p>
                            <h4>Technology</h4>
                            <h5>Unity3D, C#, custom HLSL/Cg shaders, R, Blender</h5>
                            <p>
                                The application is built in Unity3D and advanced computer graphics techniques were employed for creating custom effects.
                                In order to simultaneously show multiple environments, stencil buffer and a multi-pass technique are used. To setup the stencil buffer, an inverted-sphere is rendered with a custom fragment shader that computes the wedge shapes and outputs a unique ID number to the stencil buffer for each wedge. Then, in a second pass, each world is rendered using a stencil test that passes only for the corresponding wedge.
                                A custom geometry shader renders over 10,000 spots on the U.S. map. A R-script was written to generate binary files from preprocessed <a href="https://www.fia.fs.fed.us/library/database-documentation/" target="_blank">the US Forest Inventory and Analysis dataset</a> to speed up the loading process of the forestry data. A custom fragment shader creates more natural ground textures, which alternates between two textures based on Perlin noise.
                            </p>
                        </div>
                    </div>
                    <!-- End .project-detail -->
                    <button class="accordion">Project Video & Details</button>
                </div>
                <!-- End .project -->
            </div>
        </div>
    </div>
    <!-- End #projects -->

    <div id="education">
        <h2 class="heading">Education</h2>
        <div class="education-block">
            <h3>University of Minnesota, Twin Cities</h3>
            <span class="education-date">2014 – Aug 2022 (expected)</span>
            <h4>PhD in Computer Science</h4>
            <ul>
                <li>Advisor: Daniel F. Keefe</li>
                <li>Specializations: Scientific Visualization, Mixed Reality, Data Storytelling</li>
            </ul>
        </div>
        <!-- End .education-block -->
        <div class="education-block">
            <h3>University of Minnesota, Twin Cities</h3>
            <span class="education-date">2012 – 2014</span>
            <h4>MS in Computer Science</h4>
            <ul>
                <li>Specializations: Computer Graphics, Mixed Reality</li>
            </ul>
        </div>
        <!-- End .education-block -->
        <div class="education-block">
            <h3>University of Minnesota, Twin Cities</h3>
            <span class="education-date">2008 – 2012</span>
            <h4>BS in Computer Science</h4>
            <ul>
                <li>Specializations: Computer Graphics, User Interfaces</li>
            </ul>
        </div>
        <!-- End .education-block -->
    </div>
    <!-- End #education -->

    <div id="experience" class="background-alt">
        <h2 class="heading">Experience</h2>
        <div id="experience-timeline">
            <div data-date="2014 – Present">
                <h3>University of Minnesota - Twin Cities, Minneapolis, MN</h3>
                <h4>Research Assistant, Interactive Visualization Lab (IVLab)</h4>
                <ul>
                    <li>Focuses on building novel interactive systems for experts in scientific, medical, and cultural heritage fields to analyze and present their data.</li>
                    <li>Collaboration with the Center for Spirituality and Healing: Developed a mobile virtual reality application to practice mindfulness techniques to mitigate lower-back pains.</li>
                    <li>Collaboration with the US National Forest Services: Developed mobile & desktop virtual reality applications to tour and analyze data-driven forests in the U.S.</li>
                    <li>Collaboration with the Medical Device Center: Developed prototypes for using 3D printed props for interacting with medical data.</li>
                    <li>Developed Unity3D plugins for using 3DUI techniques in different display devices, e.g., a 4-wall CAVE, TUIO multi-touch table, 3D TVs.</li>
                </ul>
            </div>
            <div data-date="2019 – Nov 2021 (in replacement of mandatory army service)">
                <h3>Gwangju Institute of Science and Technology, South Korea</h3>
                <h4>Researcher, Korea Culture and Technology Institute (KCTI)</h4>            
                <ul>
                    <li>Developed an interactive authoring tool capturing a live dance performance.</li>
                    <li>Designed and developed a gesture-based installation for museums to present their archived heritage data to visitors, which was showcased at the Asia Culture Center during 2020 Art Culture Week.</li>
                </ul>
            </div>
            <div data-date="Summer 2018">
                <h3>INRIA, Scalay, France</h3>
                <h4>Research Intern, Analysis and Visualization Lab (AVIZ)</h4>            
                <ul>
                    <li>Investigated ways to leverage storytelling and lightweight communication between devices for science collaboration.</li>
                    <li>Designed and implemented interactive techniques for creating lightweight data-driven presentations from exploratory data visualization software.</li>
                    <li>Developed platform-specific applications to exchange and collaborate around the created presentations in different devices, e.g., in PC, Mobile, Web</li>
                </ul>
            </div>
            <div data-date="2015 – 2018">
                <h3>University of Minnesota - Twin Cities, Minneapolis, MN</h3>
                <h4>Teaching Assistant, Computer Science Department</h4>            
                <ul>
                    <li>CSCI 4611 Programming Interactive Computer Graphics and Games (Spring 2018)</li>
                    <li>CSCI 5609 Visualization (Spring 2015)</li>
                </ul>
            </div>
            <div data-date="2011 – 2014">
                <h3>University of Minnesota - Twin Cities, Minneapolis, MN</h3>
                <h4>Programmer, Center for Magnetic Resonance Research (CMRR)</h4>            
                <ul>
                    <li>Developed a Photoshop-like JAVA application to assist pathologists with assembling scanned tissue images into a complete organ and annotating cancer boundaries.</li>
                    <li>Integrated Java3D to view drawn cancer boundaries in 3D and implemented corresponding interaction functionalities.</li>
                </ul>
            </div>
        </div>
    </div>
    <!-- End #experience -->

    <div id="skills">
        <h2 class="heading">Skills</h2>
        <ul>
            <li>JavaScript</li>
            <li>Python</li>
            <li>Ruby</li>
            <li>Go</li>
            <li>Node.js</li>
            <li>AngularJs</li>
            <li>React</li>
            <li>Elixir</li>
            <li>Java</li>
            <li>C</li>
            <li>C#</li>
            <li>C++</li>
            <li>Ruby on Rails</li>
            <li>JavaScript</li>
            <li>Python</li>
            <li>Ruby</li>
            <li>Go</li>
            <li>Node.js</li>
            <li>AngularJs</li>
            <li>React</li>
            <li>Elixir</li>
            <li>Java</li>
            <li>C</li>
            <li>C#</li>
            <li>C++</li>
            <li>Ruby on Rails</li>
        </ul>
    </div>
    <!-- End #skills -->

    <div id="publication" class="background-alt">
        <h2 class="heading">Publications</h2>
        <div class="publication-block">
            <h3>Journals & Conferences</h3>
            <ul>
                <li><strong>Jung Who Nam</strong>, Krista McCullough, Joshua Tveite, Maria M. Espinosa, Charles H. Perry, Barry T. Wilson, Daniel F. Keefe. “Worlds-in-Wedges: Combining WIMs and Portals to Support Comparative Immersive Visualization of Forestry Data”. IEEE VR, Mar 2019.<br>
                    <a href=https://www.youtube.com/watch?v=okRE3JHs4SE target="_blank">https://www.youtube.com/watch?v=okRE3JHs4SE</a>
                </li>
                <li>Ethan Leng, Jonathan C Henriksen, Anthony E Rizzardi, Jin Jin, <strong>Jung Who Nam</strong>, Benjamin M Brassuer, Andrew D Johnson, Nicholas P Reder, Joseph S Koopmeiners, Stephen C Schmechel, Gregory J Metzger, “Signature maps for automatic identification of prostate cancer from colorimetric analysis of H&E-and IHC-stained histopathological specimens”. Nature Scientific Reports, May 2019</li>
                <li><strong>Jung Who Nam</strong> & Daniel F. Keefe. “Spatial Correlation: An Interactive Display of Virtual Gesture Sculpture”. IEEE VIS Arts Program, 2014, also appeared in Leonardo Journal, Feb 2017</li>
                <li>Hamza Farooq, Junqian Xu, <strong>Jung Who Nam</strong>, Daniel F. Keefe, Essa Yacoub, Tryphon Georgiou & Christophe Lenglet. “Microstructure Imaging of Crossing (MIX) White Matter Fibers from diffusion MRI”. Nature Scientific Reports, Dec 2016</li>
                <li>Metzger, G. J., Kalavagunta, C., Spilseth, B., Bolan, P. J., Li, X., Hutter, D., <strong>Nam, J.</strong>, Johnson, A. D., Henricksen, J. C., Moench, L., Konety, B., Warlick, C. A., Schmechel, S. C. & Koopmeiners, J. S.  “Detection of Prostate Cancer: Quantitative Multiparametric MR Imaging Models Developed Using Registered Correlative Histopathology”. Radiology, June 2016</li>    
            </ul>
            <hr>
            <h3>Posters</h3>
            <ul>
                <li><strong><i>(Best Poster Award)</i></strong>
                    <strong>Jung Who Nam</strong>, Charles H. Perry, Barry T. Wilson, Daniel F. Keefe, “Linked View Visualization Using Clipboard-Style Mobile VR: Application to Communicating Forestry Data”. IEEE VIS, 2019<br>
                    <a href=https://www.youtube.com/watch?v=vhv6tA6IIUk target="_blank">https://www.youtube.com/watch?v=vhv6tA6IIUk</a>
                </li>
                <li>Narae Park, Yohan Hong, Hyunjeong Pak, <strong>Jung Who Nam</strong>, Kyoungsu Kim, Junbom Pyo, Kyungwon Gil, Kyoobin Lee, "Effects of Age and Motivation for Visiting on AR Museum Experiences”. VRST, 2019</li>
                <li>Marcos Molina, Jason A. Grafft, Jon Chaika, <strong>Jung Who Nam</strong>, Matthew Quast, Co Duong, Alex Otto, Nicolas Newman, Robert Acton, Mojca Konia, “Increasing Survival of Health Care Personnel during an Active Shooter Attack: Establishing Face Validity of an Interactive Simulation Training as a Better Teaching Modality”. American College of Surgeons (ACS) conference, 2017</li>
                <li>Daniel F. Keefe, Gert Bronfort, Roni Evans, Alex Haley, Joseph Jolton, Francis J. Keefe, Lana Yarosh, Anna Tarberko, <strong>Jung Who Nam</strong>, Linda Hanson, Haiwei Ma. “VR for Health: Patient-Specific Virtual Reality Environments for Mindfulness-Based Healing”. University of Minnesota’s Institute for Engineering in Medicine (IEM) Workshop 2016</li>
                <li><strong>Jung Who Nam</strong>, Chaitanya Kalavagunta, Stephen C. Dankbar, Johnathan Henricksen, Stephen C.  Schmechel, Gregory J. Metzger. “JPStitch 2.0: a Software for Volumetric Reconstruction and Analysis of Digitized Pathology”. Donald Gleason Conference 2013</li>    
            </ul>
        </div>
        <!-- End .publication-block -->
    </div>
    <!-- End #publication -->

    <div id="contact">
        <h2>Get in Touch</h2>
        <div id="contact-form">
            <form method="POST" action="https://formspree.io/email@email.com">
                <input type="hidden" name="_subject" value="Contact request from personal website" />
                <input type="email" name="_replyto" placeholder="Your email" required>
                <textarea name="message" placeholder="Your message" required></textarea>
                <button type="submit">Send</button>
            </form>
        </div>
        <!-- End #contact-form -->
    </div>
    <!-- End #contact -->

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
                    <p>
                        Copyright &copy; 2020 YOUR NAME
                    </p>
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
                <div class="col-sm-5 social">
                    <ul>
                        <li>
                            <a href="https://github.com/" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://stackoverflow.com/" target="_blank"><i class="fa fa-stack-overflow" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://linkedin.com/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://www.facebook.com/" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://twitter.com/" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://plus.google.com/" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.js"></script>
</body>

</html>
